{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁTICA GUIADA: Otimização de modelos II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na aula passada abordamos um processo de busca automática pelos melhores hiperparâmetros. Na prática, para usar esse método precisamos:\n",
    "\n",
    "1. Dividir os dados em treino e teste. Lembrando que, para conjuntos maiores $(>1 MM)$ dividimos em treino, teste e validação;\n",
    "2. Definir uma malha de hiperparâmetros (checar na biblioteca original os hiperparâmetros dos algoritmos a serem utilizados);\n",
    "3. Definir o tipo de validaçao cruzada (para classificação, usar [`StratifiedKFold`](https://towardsdatascience.com/how-to-train-test-split-kfold-vs-stratifiedkfold-281767b93869));\n",
    "4. Definir um método de busca (até agora vimos que [`Grid Search`](https://medium.datadriveninvestor.com/an-introduction-to-grid-search-ff57adcc0998) e hoje veremos [`Randomized Search`](https://towardsdatascience.com/random-search-vs-grid-search-for-hyperparameter-optimization-345e1422899d)).\n",
    "\n",
    "#### Para cada combinação de hiperparâmetros definidos pelas malhas, o algoritmo realiza uma validação cruzada, o que lhe permitirá estimar o erro em produção para aquele conjunto específico. No final, ele nos retorna o conjunto de hiperparâmetros para o qual o erro estimado é mínimo.\n",
    "\n",
    "#### No final, devemos sempre treinar nossos dados no `X_train` e avaliar a performance no `X_test`, ainda não visto. Essa será a performance estimada em produção.\n",
    "\n",
    "- OBS 1 : Caso o conjunto de dados seja relativamente grande, não será realizada [validação cruzada](https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f). Apenas um processo iterativo e automático de busca será realizado. Nesse caso, o algoritmo retorna pra gente a combinação que produz o menor erro no conjunto de validação. No final, treinamos o modelo no `X_train` e estimamos a performance no final utilizando o `X_test`.\n",
    "\n",
    "- OBS 2: Em um conjunto menor de dados, seria interessante utilizar um método de validação conhecido como [`Nested Cross Validation`](https://weina.me/nested-cross-validation/).\n",
    "\n",
    "- OBS 3: No caso de dados grandes, não precisamos da validaçao cruzada, então não faz sentido utilizar `GridSearchCV` ou `RandomizedSearchCV`. Podemos, em vez disso, utilizar as classes [`ParameterGrid`](https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html) e [`ParameterSampler`](https://towardsdatascience.com/automated-machine-learning-using-python3-7-improving-efficiency-in-model-development-8c3574febc0b) do [`sklearn`](https://machinelearningmastery.com/scikit-optimize-for-hyperparameter-tuning-in-machine-learning/) para realizar nosso processo de busca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos a `grid` de parâmetros da mesma forma que aprendemos, mas não usaremos `GridSearchCV`. Em vez disso, utilizaremos a clase `ParameterGrid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos uma rede de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': [1, 2]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir daí, criamos o grid com todas as combinações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterGrid at 0x1a1c2baad0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizamos a separação do `dataframe` em subconjuntos de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, \n",
    "                                   stratify = df['species'], \n",
    "                                   test_size = 0.15, \n",
    "                                   random_state = 123\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos criar nosso conjunto de validação a partir do conjunt ode treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_diabetes.shape[0]: 150\n",
      "n_rows_validation: 22\n",
      "percent_validation: 0.17\n"
     ]
    }
   ],
   "source": [
    "n_rows_validation = int(0.15 * df.shape[0])\n",
    "percent_validation = round((n_rows_validation / df_train.shape[0]), 2)\n",
    "\n",
    "print('df_diabetes.shape[0]:', df.shape[0])\n",
    "print('n_rows_validation:', n_rows_validation)\n",
    "print('percent_validation:', percent_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df_train, \n",
    "                                    stratify = df_train['species'], \n",
    "                                    test_size = percent_validation, \n",
    "                                    random_state = 123\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciamos um objeto que recebe o modelo de kNN e separamos nossos subconjuntos de treino `train`, teste `test` e validação `val`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n",
      "23 23\n",
      "22 22\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train.drop('species', axis = 1), df_train['species']\n",
    "X_test, y_test = df_test.drop('species', axis = 1), df_test['species']\n",
    "X_val, y_val = df_val.drop('species', axis = 1), df_val['species']\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "print(len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combinacao: {'n_neighbors': 1}\n",
      "validation_error: [0.4090909090909091]\n",
      "combinacao: {'n_neighbors': 2}\n",
      "validation_error: [0.4090909090909091, 0.4090909090909091]\n"
     ]
    }
   ],
   "source": [
    "validation_error = []\n",
    "for combinacao in ParameterGrid(param_grid):\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_val_calc = knn.predict(X_train)    \n",
    "    y_val = knn.predict(X_val)\n",
    "    y_val_calc_sample = pd.DataFrame(y_val_calc).head(n_rows_validation)\n",
    "    erro = accuracy_score(y_val_calc_sample, y_val)\n",
    "\n",
    "    #y_pred = knn.predict(X_train)    \n",
    "    #erro = accuracy_score(y_pred, y_val)\n",
    "    \n",
    "    validation_error.append(erro)\n",
    "    print('combinacao:', combinacao)\n",
    "    print('validation_error:', validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_val_calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na prática, não faremos validação cruzada. Apenas iremos treinar e testar um modelo para cada combinação do dicionário acima e checar qual retorna para nós o menor erro de validação. Com isso, treinamos nosso modelo no`X_train` e testamos sua performance dele no `X_Test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDq8-uvlIQeE"
   },
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O [`Grid Search`](https://towardsdatascience.com/gridsearch-the-ultimate-machine-learning-tool-6cd5fb93d07) pode ser considerado um método para que escolhe o melhor conjunto de hiperparâmetros por exaustão. No `Grid Search`, o cientista de dados configura uma grade de valores de hiperparâmetros e, para cada combinação, treina um modelo e pontua nos dados de teste. Nessa abordagem, todas as combinações de valores de hiperparâmetros são testadas, o que pode ser muito ineficiente. Por exemplo, pesquisar $20$ valores de parâmetros diferentes para cada um dos $4$ parâmetros exigirá $160,000$ tentativas de validação cruzada. Isso equivale a $1,600,000$ ajustes de modelo e $1,600,000$ previsões se a validação cruzada de $10$ dobras for usada. Embora o [`Scikit Learn`](https://scikit-learn.org/stable/tutorial/statistical_inference/index.html) ofereça a função `GridSearchCV` para simplificar o processo, seria uma execução extremamente cara em termos de capacidade e tempo de computação.\n",
    "\n",
    "#### Em contraste,o [`Randomized Search`](https://vitalflux.com/randomized-search-explained-python-sklearn-example/) configura uma grade de valores de hiperparâmetros e seleciona combinações aleatórias para treinar o modelo e avaliar o erro. Isso permite que você controle explicitamente o número de combinações de parâmetros que são tentadas. O número de iterações de pesquisa é definido com base no tempo ou recursos. O `Scikit Learn` oferece a função [`RandomizedSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) para esse processo.\n",
    "\n",
    "#### Embora seja possível que `RandomizedSearchCV` não encontre um resultado tão preciso quanto `GridSearchCV`, ele surpreendentemente escolhe o melhor resultado com mais frequência do que não e em uma fração do tempo que o `GridSearchCV` levaria. Com os mesmos recursos, o `Random Search` pode até superar o `Grid Search`. Isso pode ser visualizado no gráfico abaixo quando parâmetros contínuos são usados.\n",
    "\n",
    "<img src=\"gridSearchRandomSearch.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O `RandomizedSearch` é baseado em distribuições, ou seja, ele pode selecionar valores entre um intervalo de valores, diferentemente do `GridSearch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParameterSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quando queremos usar uma busca aleatória (`Random Search`), mas sem validação cruzada, podemos usar a classe [`ParameterSampler()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterSampler.html) do `sklearn`. Essa classe vai receber o dicionário com as distribuições dos parâmetros e o número de iterações. \n",
    "\n",
    "#### A cada iteração em um laço (`loop`), ele vai gerar um valor aleatório de combinação de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import loguniform, uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict()\n",
    "param_grid['solver'] = ['newton-cg', \n",
    "                        'lbfgs', \n",
    "                        'liblinear'\n",
    "                       ]\n",
    "param_grid['penalty'] = ['none', \n",
    "                         'l1', \n",
    "                         'l2', \n",
    "                         'elasticnet'\n",
    "                        ]\n",
    "param_grid['C'] = loguniform(1e-5, \n",
    "                             100\n",
    "                            )\n",
    "param_grid['whatever'] = randint(1, \n",
    "                                 1000\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterSampler at 0x1a1c325950>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterSampler(param_grid, \n",
    "                 n_iter = 10, \n",
    "                 random_state = 123\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.750385268090156, 'penalty': 'l2', 'solver': 'liblinear', 'whatever': 989}\n",
      "{'C': 0.6857944800896927, 'penalty': 'l1', 'solver': 'liblinear', 'whatever': 124}\n",
      "{'C': 2.8853223070403433, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 114}\n",
      "{'C': 0.023255373037796706, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 943}\n",
      "{'C': 0.24616089675634506, 'penalty': 'l1', 'solver': 'liblinear', 'whatever': 254}\n",
      "{'C': 0.7299384488053402, 'penalty': 'none', 'solver': 'newton-cg', 'whatever': 818}\n",
      "{'C': 0.00018942710113933008, 'penalty': 'l2', 'solver': 'newton-cg', 'whatever': 40}\n",
      "{'C': 0.9689720939864422, 'penalty': 'elasticnet', 'solver': 'newton-cg', 'whatever': 958}\n",
      "{'C': 8.831257714012057, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 861}\n",
      "{'C': 1.140522028920257, 'penalty': 'l1', 'solver': 'lbfgs', 'whatever': 631}\n"
     ]
    }
   ],
   "source": [
    "for combinacao in ParameterSampler(param_grid, n_iter = 10, random_state = 123):\n",
    "    print(combinacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por último, iremos falar da [`busca bayesiana`](). [Thomas Bayes](https://www.britannica.com/biography/Thomas-Bayes) trouxe diversas contribuições para a estatística, a busca bayesiana vai se basear em probabilidades e em atualização dessa probabilidade, tal como no [teorema de bayes]().\n",
    "\n",
    "<img src=\"BayesianSearch.png\" width=800>\n",
    "\n",
    "#### O grande ponto de falha dos métodos que vimos é que eles não levam em consideração erros do passado. Se uma determinada região do espaço trouxe performances abaixo do esperado, é razoável parar de procurar naquela região.\n",
    "\n",
    "#### As abordagens bayesianas, em contraste com o `Random Search` ou `Grid Search`, rastreiam os resultados de avaliações anteriores que usam para formar um modelo probabilístico de mapeamento de hiperparâmetros. Dessa forma, ao criar esse modelo probabilístico, o algoritmo consegue estimar o ponto no espaço em que a probabilidade de obter um erro menor é maior. \n",
    "\n",
    "#### Na literatura, esse modelo é chamado de [`surrogate`]() da função objetivo e é representado como $P(y | x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos fazer uma aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separamos nosso `dataset` em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 120, 30)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state = 123\n",
    "                                                   )\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicaremos o método [`StratifiedKFold()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), um objeto de validação cruzada, que é uma variação de `KFold`, que retorna dobras estratificadas. As dobras são feitas preservando-se o percentual de amostras de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified kfold\n",
    "skf = StratifiedKFold(n_splits = 10, \n",
    "                      shuffle = True, \n",
    "                      random_state = 123\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciamos um modelo kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(n_neighbors = range(1, 31))\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': range(1, 31)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E realizamos uma busca aleatórea da melhor combinação de hiperparâmetros com o método [`RandomizedSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search\n",
    "#%time\n",
    "random_search = RandomizedSearchCV(knn, \n",
    "                                   param_grid, \n",
    "                                   n_iter = 10,\n",
    "                                   cv = skf, \n",
    "                                   scoring = 'neg_log_loss', \n",
    "                                   verbose = 1, \n",
    "                                   random_state = 123\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=123, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'n_neighbors': range(1, 31)},\n",
       "                   random_state=123, scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07803933303339768"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "#%time\n",
    "grid_search = GridSearchCV(knn, \n",
    "                           param_grid, \n",
    "                           cv = skf, \n",
    "                           scoring = 'neg_log_loss', \n",
    "                           verbose = 1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 31)}, scoring='neg_log_loss',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07803933303339768"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note que o `Grid search` demorou mais que o dobro de tempo para rodar. No final, o `Random search` conseguiu encontrar o melhor número de vizinhos mais próximos, com menos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GridSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
